{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#O-que-veremos?\" data-toc-modified-id=\"O-que-veremos?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>O que veremos?</a></span></li><li><span><a href=\"#Requisitos-Básicos\" data-toc-modified-id=\"Requisitos-Básicos-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Requisitos Básicos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Teoria\" data-toc-modified-id=\"Teoria-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Teoria</a></span></li><li><span><a href=\"#Técnico\" data-toc-modified-id=\"Técnico-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Técnico</a></span></li></ul></li><li><span><a href=\"#Criando-Pipelines\" data-toc-modified-id=\"Criando-Pipelines-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Criando Pipelines</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sem-Pipeline\" data-toc-modified-id=\"Sem-Pipeline-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Sem Pipeline</a></span></li><li><span><a href=\"#Com-Pipeline\" data-toc-modified-id=\"Com-Pipeline-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Com Pipeline</a></span></li></ul></li><li><span><a href=\"#Dissecando-com_pipeline.py\" data-toc-modified-id=\"Dissecando-com_pipeline.py-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Dissecando com_pipeline.py</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linhas-[10,-27]\" data-toc-modified-id=\"Linhas-[10,-27]-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Linhas [10, 27]</a></span></li><li><span><a href=\"#Linhas-[29,-31]\" data-toc-modified-id=\"Linhas-[29,-31]-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Linhas [29, 31]</a></span></li><li><span><a href=\"#Linhas-[34,-36]\" data-toc-modified-id=\"Linhas-[34,-36]-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Linhas [34, 36]</a></span></li><li><span><a href=\"#Linhas-39,-41-e-46\" data-toc-modified-id=\"Linhas-39,-41-e-46-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Linhas 39, 41 e 46</a></span></li></ul></li><li><span><a href=\"#Importante\" data-toc-modified-id=\"Importante-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Importante</a></span></li><li><span><a href=\"#Esquema-Pipeline\" data-toc-modified-id=\"Esquema-Pipeline-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Esquema Pipeline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Usando-o-.fit()\" data-toc-modified-id=\"Usando-o-.fit()-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Usando o .fit()</a></span></li><li><span><a href=\"#Usando-.transform()\" data-toc-modified-id=\"Usando-.transform()-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Usando .transform()</a></span></li><li><span><a href=\"#Usando-.fit_transform()\" data-toc-modified-id=\"Usando-.fit_transform()-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Usando .fit_transform()</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que veremos? \n",
    "\n",
    "Em 99% dos modelos de Machine Learning criados(fonte eu mesmo), nós teremos que pré-processar e transformar os dados antes deles serem passados para um estimador do *scikit-learn*.<br>\n",
    "\n",
    "O problema disso é que nós teremos muitas linhas de código com objetos que possuem os mesmos métodos .fit() e .transform() e um objeto final com .fit() e .predict(). Nós aprenderemos a colocar todos esses objetos dentro um único PIPELINE, assim usaremos apenas o PIPELINE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requisitos Básicos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoria\n",
    "Não há nenhuma teoria básica que seja condição necessária para que você consiga seguir com esse notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnico \n",
    "- Python | Requisitos em **02-Python-Packages-Libraries/0-Python**\n",
    "    - Básico de Orientação a Objetos. Somente saber o que são objetos, classes, métodos, atributos etc. Nomenclatura e terminologia básicas\n",
    "    - Imports de bibliotecas\n",
    "- NumPy | Requisitos em **02-Python-Packages-Libraries/01-NumPy**\n",
    "    - Arrays\n",
    "    - Manipulação básica de arrays\n",
    "- Pandas | Requisitos em **02-Python-Packages-Libraries/02-Pandas**\n",
    "    - Leitura de dados\n",
    "    - Dataframes e Series\n",
    "    - Manipulação básica dos dois acima\n",
    "- Scikit-Learn | Requisitos em **02-Python-Packages-Libraries/03-Scikit-Learn/00-Getting-Started**\n",
    "    - Transformadores e pré-processadores\n",
    "    - Fit e predict com estimadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando Pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sem Pipeline\n",
    "\n",
    "Primeiro, vamos fazer um modelo sem usar o Pipeline e ver como o código ficaria.<br>\n",
    "\n",
    "Vamos usar o dataset [Titanic do Kaggle](https://www.kaggle.com/c/titanic), entre no link para saber mais sobre a competição no próprio [Kaggle](https://www.kaggle.com/).<br>\n",
    "\n",
    "Alguns pontos:\n",
    "- A coluna PassengerId será usada como index\n",
    "- Usaremos apenas as features Age e Fare, as duas serão nossa Design Matrix X\n",
    "    - Age tem dados faltantes\n",
    "- Survived é o nosso Target Values y\n",
    "- Não iremos separar os dados em treino e teste. Nunca faça isso, aqui é somente um exemplo para mostrarmos o funcionamento geral do Pipeline, depois iremos mostrar com profundidade tudo o que temos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de dados faltantes nas features\n",
      "Age     19.87\n",
      "Fare     0.00\n",
      "dtype: float64\n",
      "Veja que a feature Age tem ~20% de dados faltantes\n",
      "--------------------------------------------------\n",
      "\n",
      "Acc nos mesmos dados que treinamos: 65.43%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------sem_pipeline.py------\n",
    "\n",
    "Script que mostra duas transformacoes:\n",
    "    - Inserimos a media onde temos valores faltantes\n",
    "    - Fazer o StandardScaler dos dados apos inserir os dados faltantes\n",
    "Apos as duas transformacoes, nos usamos o estimador LogisticRegression\n",
    "Repare na quantidade de passos que devemos fazer.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "PATH_FILE = 'data/titanic.csv'\n",
    "USE_COLS = ['PassengerId', 'Survived', 'Age', 'Fare']\n",
    "\n",
    "df_titanic = pd.read_csv(PATH_FILE, usecols=USE_COLS, index_col='PassengerId')\n",
    "\n",
    "X = df_titanic.drop(columns='Survived')\n",
    "y = df_titanic.loc[:, 'Survived']\n",
    "\n",
    "print('Porcentagem de dados faltantes nas features')\n",
    "print(f'{(X.isna().mean()*100).round(2)}')\n",
    "print('Veja que a feature Age tem ~20% de dados faltantes')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# inserindo a media em dados faltantes\n",
    "# vamos usar primeiro .fit() e depois .transform()\n",
    "imputer.fit(X)\n",
    "X_t_impute = imputer.transform(X)\n",
    "\n",
    "# fazendo o scaling dos dados com StandardScaler\n",
    "# apos inserirmos dados vazios\n",
    "scaler.fit(X_t_impute)\n",
    "X_t_scaler = scaler.transform(X_t_impute)\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_t_scaler, y)\n",
    "\n",
    "# vamos ver a acuracia do modelo\n",
    "# estamos fazendo isso nos mesmos \n",
    "# dados que treinamos, nunca faca isso\n",
    "acc = log_reg.score(X_t_scaler, y)*100\n",
    "print(f'\\nAcc nos mesmos dados que treinamos: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja a saída de cada transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>32.0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age     Fare\n",
       "PassengerId               \n",
       "1            22.0   7.2500\n",
       "2            38.0  71.2833\n",
       "3            26.0   7.9250\n",
       "4            35.0  53.1000\n",
       "5            35.0   8.0500\n",
       "...           ...      ...\n",
       "887          27.0  13.0000\n",
       "888          19.0  30.0000\n",
       "889           NaN  23.4500\n",
       "890          26.0  30.0000\n",
       "891          32.0   7.7500\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design Matrix Original\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.        ,  7.25      ],\n",
       "       [38.        , 71.2833    ],\n",
       "       [26.        ,  7.925     ],\n",
       "       ...,\n",
       "       [29.69911765, 23.45      ],\n",
       "       [26.        , 30.        ],\n",
       "       [32.        ,  7.75      ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design Matrix apos inserir a media\n",
    "# onde tinhamos dados faltantes\n",
    "X_t_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5924806 , -0.50244517],\n",
       "       [ 0.63878901,  0.78684529],\n",
       "       [-0.2846632 , -0.48885426],\n",
       "       ...,\n",
       "       [ 0.        , -0.17626324],\n",
       "       [-0.2846632 , -0.04438104],\n",
       "       [ 0.17706291, -0.49237783]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design Matrix apos inserir a media\n",
    "# e fazer o standard scaler\n",
    "X_t_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Com Pipeline\n",
    "\n",
    "Vamos reproduzir as mesmas transformações acima, mas dessa vez vamos usar o Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de dados faltantes nas features\n",
      "Age     19.87\n",
      "Fare     0.00\n",
      "dtype: float64\n",
      "Veja que a feature Age tem ~20% de dados faltantes\n",
      "--------------------------------------------------\n",
      "\n",
      "Acc nos mesmos dados que treinamos: 65.43%\n",
      "--------------------------------------------------\n",
      "\n",
      "10 primeiras previsoes direto com o pipeline\n",
      "[0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------com_pipeline.py------\n",
    "Faremos exatamente as mesmas coisas que\n",
    "fizemos em sem_pipeline.py, mas vamos fazer\n",
    "uso do Pipeline.\n",
    "\n",
    "Veja como reduzimos tudo a apenas uma linha, o Pipeline\n",
    "ja treina e faz as transformacoes para a gente\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "PATH_FILE = 'data/titanic.csv'\n",
    "USE_COLS = ['PassengerId', 'Survived', 'Age', 'Fare']\n",
    "\n",
    "df_titanic = pd.read_csv(PATH_FILE, usecols=USE_COLS, index_col='PassengerId')\n",
    "\n",
    "X = df_titanic.drop(columns='Survived')\n",
    "y = df_titanic.loc[:, 'Survived']\n",
    "\n",
    "print('Porcentagem de dados faltantes nas features')\n",
    "print(f'{(X.isna().mean()*100).round(2)}')\n",
    "print('Veja que a feature Age tem ~20% de dados faltantes')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# instanciando o pipeline com os passos que queremos\n",
    "pipeline = Pipeline([('ImputeMean', imputer), # primeiro ele insere a media\n",
    "                     ('StandardScaler', scaler), # segundo ele faz o StandardScaler \n",
    "                     ('LogisticRegression', log_reg)]) # terceiro ele treina o estimador\n",
    "\n",
    "# usamos o .fit() e ele ja faz todos os passos acima\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "acc = pipeline.score(X, y)*100\n",
    "print(f'\\nAcc nos mesmos dados que treinamos: {acc:.2f}%')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# podemos fazer previsoes apos dar .fit()\n",
    "y_pred = pipeline.predict(X)\n",
    "print('\\n10 primeiras previsoes direto com o pipeline')\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja os passos(steps) do Pipeline que criamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passos(steps) do Pipeline\n",
      "Pipeline(steps=[('ImputeMean', SimpleImputer()),\n",
      "                ('StandardScaler', StandardScaler()),\n",
      "                ('LogisticRegression', LogisticRegression(random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "print('Passos(steps) do Pipeline')\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colocando a configurção display='diagram', conseguimos ver o Pipeline com uma representação em HTML quando usamos Jupyter-Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"43eab71d-70a9-4665-aa7f-1096e96515ec\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"43eab71d-70a9-4665-aa7f-1096e96515ec\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('ImputeMean', SimpleImputer()),\n",
       "                ('StandardScaler', StandardScaler()),\n",
       "                ('LogisticRegression', LogisticRegression(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"20b70c40-a52b-460a-8190-ee48e0cd2cee\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"20b70c40-a52b-460a-8190-ee48e0cd2cee\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"fe8e9eb4-34b1-4da4-93aa-00ee9391c297\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"fe8e9eb4-34b1-4da4-93aa-00ee9391c297\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"608e8757-1589-4ad5-8b17-de0a962ba1e3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"608e8757-1589-4ad5-8b17-de0a962ba1e3\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ImputeMean', SimpleImputer()),\n",
       "                ('StandardScaler', StandardScaler()),\n",
       "                ('LogisticRegression', LogisticRegression(random_state=42))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dissecando com_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linhas [10, 27] \n",
    "Não vamos nos concentrar no intervalo de linhas [10, 27], já que elas são requisitos básicos para esse notebook. Use as referências indicadas no começo do notebook caso sinta alguma difilculdade em entender o que está acontecendo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linhas [29, 31]\n",
    "\n",
    "- 29\n",
    "```python\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "```\n",
    "    - instanciamos o SimpleImputer, que irá inserir a média onde temos dados faltantes\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "- 30\n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "```\n",
    "    - instanciamos o StandardScaler, que irá aprender a média e o desvio padrão dos dados e depois fará a transformaçã $$z = \\frac{(x - \\bar{u})}{\\bar{s}}$$\n",
    "<br>\n",
    "<br>\n",
    "<br>    \n",
    "- 31\n",
    "```python\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "```\n",
    "    - instanciamos o estimador LogisticRegression com o random_state em 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linhas [34, 36]\n",
    "\n",
    "```python\n",
    "pipeline = Pipeline([('ImputeMean', imputer),\n",
    "                     ('StandardScaler', scaler),\n",
    "                     ('LogisticRegression', log_reg)])\n",
    "```\n",
    "\n",
    "Criamos o pipeline, veja que temos que passar uma lista de tuplas para dentro do **Pipeline()**, a tupla tem dois elementos\n",
    "- Primeiro elemento: nome do passo, para que você possa acessar posteriormente\n",
    "- Segundo elemento: o objeto que que fará a transformação ou estimador\n",
    "\n",
    "Vamos adiantar aqui, mas caso queira acessar os passos, basta fazer igual o exemplo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ImputeMean': SimpleImputer(),\n",
       " 'StandardScaler': StandardScaler(),\n",
       " 'LogisticRegression': LogisticRegression(random_state=42)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Usando o atributo named_steps, nos\n",
    "criamos um dicionario onde a chave eh o nome do passo\n",
    "que voce deu e o valor eh o objeto em si.\n",
    "\"\"\"\n",
    "pipeline.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e17df4c5-7797-440b-8493-09dd9424696b\" type=\"checkbox\" checked><label class=\"sk-toggleable__label\" for=\"e17df4c5-7797-440b-8493-09dd9424696b\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Para acessar, basta usar colchetes e passar\n",
    "a chave que voce quiser\n",
    "\"\"\"\n",
    "pipeline.named_steps['StandardScaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media e desvio padrao aprendidos pelo StandardScaler\n",
      "Media Age: 29.70 ||| Media Fare: 32.20\n",
      "Desvio Padrao Age: 12.99 ||| Desvio Padrao Fare: 49.67\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Nos conseguimos acessar os atributos dos\n",
    "transformadores e ver o que ele aprendeu.\n",
    "Veja este exemplo com o StandardScaler\n",
    "\"\"\"\n",
    "mean = pipeline.named_steps['StandardScaler'].mean_\n",
    "std = pipeline.named_steps['StandardScaler'].scale_\n",
    "\n",
    "print('Media e desvio padrao aprendidos pelo StandardScaler')\n",
    "print(f'Media Age: {mean[0]:.2f} ||| Media Fare: {mean[1]:.2f}')\n",
    "print(f'Desvio Padrao Age: {std[0]:.2f} ||| Desvio Padrao Fare: {std[1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media aprendida pelo SimpleImputer\n",
      "Media Age: 29.70\n",
      "Media Fare: 32.20\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Nos conseguimos acessar os atributos dos\n",
    "transformadores e ver o que ele aprendeu.\n",
    "Veja este exemplo com o SimpleImputer\n",
    "\"\"\"\n",
    "mean_age = pipeline.named_steps['ImputeMean'].statistics_[0]\n",
    "mean_fare = pipeline.named_steps['ImputeMean'].statistics_[1]\n",
    "\n",
    "print('Media aprendida pelo SimpleImputer')\n",
    "print(f'Media Age: {mean_age:.2f}')\n",
    "print(f'Media Fare: {mean_fare:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linhas 39, 41 e 46 \n",
    "\n",
    "- 39\n",
    "```python\n",
    "pipeline.fit(X, y)\n",
    "```\n",
    "    - Após criarmos o pipeline, damos um fit direto nos dados. Lembre-se, aqui estamos dando apenas um exemplo, esse .fit() deve ser nos dados de treino.\n",
    "    - O pipeline já faz tudo de uma vez para você na sequência de passos que você colocou.\n",
    "        - 1) ele insere a média calculada pelo SimpleImputer onde temos dados faltantes\n",
    "        - 2) ele faz a transformação com o StandardScaler\n",
    "        - 3) ele treina a LogisticRegression, esta é o nosso estimador para fazer previsões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 41\n",
    "```python\n",
    "acc = pipeline.score(X, y)*100\n",
    "```\n",
    "    - Após darmos o .fit() com o pipeline, podemos usar o método score da própria LogisticRegression. Esse score é a acurácia dos dados que passarmos para ela, no nosso caso, X e y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 41\n",
    "```python\n",
    "y_pred = pipeline.predict(X)\n",
    "```\n",
    "    - Após dar o .fit(), podemos usar o pipeline para fazer previsões. Ele automaticamente dá um .transform() com o SimpleImputer e com o StandardScaler e por último usa o .predict() da LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importante\n",
    "\n",
    "Nós não separamos em dados de treino e teste. Vamos bater sempre nessa tecla, o método .fit() sempre deve ser usado nos dados de treino e nunca nos de teste. Para os dados de teste, devemos usar apenas o método .transform(). Para não ficar decorando isso, basta usar o Pipeline e ele faz tudo para você."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Esquema Pipeline\n",
    "\n",
    "Primeiro, nós instanciamos tudo que usaremos:\n",
    "- Círculo: SimpleImputer(strategy='mean'), que calcula a média e insere onde temos dados faltantes\n",
    "- Triângulo: StandardScaler(), que calcula a média $\\bar{u}$ e o desvio padrão $\\bar{s}$ dos dados e depois faz a transformação $$z = \\frac{(x - \\bar{u})}{\\bar{s}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![INSTANCE-OBJECTS](images/04_01_instance_objects.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intanciamos o pipeline, passando para o Pipeline uma lista de tuplas, onde:\n",
    "- Primeiro elemento da tupla: nome do passo, isso serve para acessarmos posteriormente\n",
    "- Segundo elemento da tupla: objeto em si que fará a transformação ou .fit() e .predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![INSTANCE-PIPE](images/04_02_instance_pipe.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando o .fit() \n",
    "\n",
    "Como sempre, o .fit() apenas aprende alguma coisa, no nosso caso:\n",
    "- Passo **Impute**\n",
    "    - aprende a média dos dados, 4.333\n",
    "- Passo **Scaler**:\n",
    "    - aprende a média dos dados, 4.333\n",
    "    - apende o desvio padrão dos dados, 3.488\n",
    "\n",
    "Conseguimos acessar os passos através do atributo .named_steps e verificar os parâmetros aprendidos de cada transformador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FIT-PIPE](images/04_03_fit_pipeline.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando .transform()\n",
    "Usando o .transform(), nós efetivamente fazemos as trasnformações com os parâmetros aprendidos pelo .fit()\n",
    "\n",
    "- 1:\n",
    "    - com a média 4.333 aprendida, o .transform() insere onde temos dados vazios(NaN)\n",
    "- 2:\n",
    "    - com a média $\\bar{u}=4.333$ e o desvio padrão $\\bar{s}=3.488$, fazemos a transformação $$z = \\frac{(x - \\bar{u})}{\\bar{s}}$$\n",
    "    em cada sample(linha) dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FIT-PIPE](images/04_04_transform_pipeline.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando .fit_transform() \n",
    "Este método já faz o .fit(), ou seja, aprende os parâmetros com os dados e já aplica a transformação, tudo de uma vez. Geralmente é ele que usamos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
