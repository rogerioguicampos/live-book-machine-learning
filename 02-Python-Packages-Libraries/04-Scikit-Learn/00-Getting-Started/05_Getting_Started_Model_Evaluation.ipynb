{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#O-que-veremos?\" data-toc-modified-id=\"O-que-veremos?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>O que veremos?</a></span></li><li><span><a href=\"#Requisitos-Básicos\" data-toc-modified-id=\"Requisitos-Básicos-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Requisitos Básicos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Teoria\" data-toc-modified-id=\"Teoria-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Teoria</a></span></li><li><span><a href=\"#Técnico\" data-toc-modified-id=\"Técnico-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Técnico</a></span></li></ul></li><li><span><a href=\"#Avaliando-modelos\" data-toc-modified-id=\"Avaliando-modelos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Avaliando modelos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Avaliando-Regressão-com-Holdout\" data-toc-modified-id=\"Avaliando-Regressão-com-Holdout-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Avaliando Regressão com Holdout</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dissecando-eval_diff_data_reg.py\" data-toc-modified-id=\"Dissecando-eval_diff_data_reg.py-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Dissecando eval_diff_data_reg.py</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linhas-[8,-21]\" data-toc-modified-id=\"Linhas-[8,-21]-3.1.1.1\"><span class=\"toc-item-num\">3.1.1.1&nbsp;&nbsp;</span>Linhas [8, 21]</a></span></li><li><span><a href=\"#Linha-24\" data-toc-modified-id=\"Linha-24-3.1.1.2\"><span class=\"toc-item-num\">3.1.1.2&nbsp;&nbsp;</span>Linha 24</a></span></li><li><span><a href=\"#Linhas-29-e-32\" data-toc-modified-id=\"Linhas-29-e-32-3.1.1.3\"><span class=\"toc-item-num\">3.1.1.3&nbsp;&nbsp;</span>Linhas 29 e 32</a></span></li></ul></li></ul></li><li><span><a href=\"#Avaliando-Classificação-com-Holdout\" data-toc-modified-id=\"Avaliando-Classificação-com-Holdout-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Avaliando Classificação com Holdout</a></span></li><li><span><a href=\"#Avaliando-Regressão-e-Classificação-com-Cross-Validation\" data-toc-modified-id=\"Avaliando-Regressão-e-Classificação-com-Cross-Validation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Avaliando Regressão e Classificação com Cross-Validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dissecando-cross_val_classification.py\" data-toc-modified-id=\"Dissecando-cross_val_classification.py-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Dissecando cross_val_classification.py</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linhas-[8,-22]\" data-toc-modified-id=\"Linhas-[8,-22]-3.3.1.1\"><span class=\"toc-item-num\">3.3.1.1&nbsp;&nbsp;</span>Linhas [8, 22]</a></span></li><li><span><a href=\"#Linha-27\" data-toc-modified-id=\"Linha-27-3.3.1.2\"><span class=\"toc-item-num\">3.3.1.2&nbsp;&nbsp;</span>Linha 27</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Esquema-Função-cross-val-score\" data-toc-modified-id=\"Esquema-Função-cross-val-score-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Esquema Função cross-val-score</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que veremos? \n",
    "\n",
    "O objetivo maior de um modelo de Machine Learning é ele se sair bem - o bem aqui é mensurado por alguma medida - em dados que ele nunca viu.<br>\n",
    "\n",
    "O problema é que nós só temos dados históricos, ou seja, dados de coisas que já aconteceram. Como podemos saber como o nosso modelo se sairá na vida real e em dados que ele nunca viu?<br>\n",
    "\n",
    "É justamente isso que veremos aqui nesse notebook, obviamente de maneira superficial num primeiro momento, mas tenham calma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requisitos Básicos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoria\n",
    "- Machine Learning Theory | Requisitos em **01-Basic-Theory/03-Basic-ML-Theory**\n",
    "    - Avaliação de modelos com holdout\n",
    "    - Avaliação e seleção de modelos com Cross-Validation\n",
    "    - Métricas para avaliar modelos\n",
    "        - Mean Squared Error\n",
    "        - Root Mean Squared Error\n",
    "        - Accuracy\n",
    "        - $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnico \n",
    "\n",
    "- Python | Requisitos em **02-Python-Packages-Libraries/0-Python**\n",
    "    - Imports de bibliotecas\n",
    "- NumPy | Requisitos em **02-Python-Packages-Libraries/01-NumPy**\n",
    "    - Arrays\n",
    "    - Manipulação básica de arrays\n",
    "- Pandas | Requisitos em **02-Python-Packages-Libraries/02-Pandas**\n",
    "    - Leitura de dados\n",
    "    - Dataframes e Series\n",
    "    - Manipulação básica dos dois acima\n",
    "- Scikit-Learn | Requisitos em **02-Python-Packages-Libraries/03-Scikit-Learn/00-Getting-Started**\n",
    "    - Fit e predict com estimadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando modelos\n",
    "\n",
    "Vamos avaliar dois modelos de Machine Learning Supervisionado, um em uma tarefa de classificação e outro em uma de regressão.<br>\n",
    "\n",
    "Na tarefa de classificação, vamos usar o dataset [Pima Indians Diabetes Database](https://www.kaggle.com/uciml/pima-indians-diabetes-database) do [Kaggle](https://www.kaggle.com/) e na tarefa de regressão iremos usar [Boston Housing](https://www.kaggle.com/schirmerchad/bostonhoustingmlnd).<br>\n",
    "\n",
    "Para maiores detalhes sobre cada problema, só entrar na página do [Kaggle](https://www.kaggle.com/) e ler a descrição de cada um."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando Regressão com Holdout\n",
    "\n",
    "Temos dois scripts, onde:\n",
    "- eval_same_data.py faz o seguinte:\n",
    "    - leitura dos dados com pd.read_csv()\n",
    "    - treina uma DecisionTreeRegressor em todos os dados que temos\n",
    "    - faz previsões nos mesmos dados que o algoritmo treinou\n",
    "    - avalia com a métrica Root Mean Squared Error as previsões que são feitas nos mesmos dados que treinamos\n",
    "- eval_diff_data.py faz o seguinte:\n",
    "    - leitura dos dados com pd.read_csv()\n",
    "    - separa aleatoriamente 30% dos dados\n",
    "    - treina uma DecisionTreeRegressor em 70% que foram separados aleatoriamente\n",
    "    - faz previsões nos 30% de dados que foram separados e que o modelo nunca viu\n",
    "    - avalia com a métrica Root Mean Squared Error as previsões que foram feitas nos dados que ele nunca viu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE nos mesmos dados que treinamos: 0.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------eval_same_data_reg.py------\n",
    "\n",
    "Script que treina e avalia uma DecisionTreeRegresssor\n",
    "nos mesmos dados. Veja que o erro eh zero\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "PATH_FILE = 'data/housing.csv'\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df_housing = pd.read_csv(PATH_FILE)\n",
    "\n",
    "X = df_housing.drop(columns='MEDV')\n",
    "y = df_housing.loc[:, 'MEDV']\n",
    "\n",
    "dec_tree = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "dec_tree.fit(X, y)\n",
    "\n",
    "# fazendo previsoes nos mesmos dados que vimos\n",
    "y_pred = dec_tree.predict(X)\n",
    "\n",
    "# avaliando com a metrica RMSE \n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "\n",
    "print(f'RMSE nos mesmos dados que treinamos: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE em dados nunca vistos: 79448.66\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------eval_diff_data_reg.py------\n",
    "\n",
    "Script que treina uma DecisionTreeRegressor em 70% dos\n",
    "dados e avalia nos 30% restantes. Veja como o erro\n",
    "ja eh diferente de zero.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "PATH_FILE = 'data/housing.csv'\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df_housing = pd.read_csv(PATH_FILE)\n",
    "\n",
    "X = df_housing.drop(columns='MEDV')\n",
    "y = df_housing.loc[:, 'MEDV']\n",
    "\n",
    "# divindo X e y em uma proporcao de 70% para treino e 30% para testar\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "dec_tree = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "# aqui estamos treinado em apenas 70% dos dados\n",
    "dec_tree.fit(X_train, y_train)\n",
    "\n",
    "# fazendo previsoes nos outros 30% que o modelo nunca viu\n",
    "y_pred = dec_tree.predict(X_test)\n",
    "\n",
    "# avaliando com a metrica RMSE as previsoes feitas em dados que nunca vimos\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'RMSE em dados nunca vistos: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dissecando eval_diff_data_reg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linhas [8, 21] \n",
    "Fazem parte dos requisitos básicos, caso não entenda o que está acontecendo nessas linhas de código, consulte as referências que estão nos requisitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linha 24\n",
    "A função *train_test_split()* divide aleatoriamente *arrays* ou matrizes(tabelas). Vamos rodar alguns testes com ela para ver o que acontece.<br>\n",
    "\n",
    "- Principais parâmetros\n",
    "    - *arrays: os dados que iremos dividir\n",
    "    - test_size: se for um float entre 0.0 e 1.0, representa a porcentagem de dados que serão separados para os dados de teste. Caso seja um int, é a quantidade absoluta de samples que iremos separar para os dados de teste.\n",
    "    - random_state: a separação é feita aleatoriamente, então em cada vez que rodarmos, teremos resultados diferentes. Como um dos pilares da Ciência é a reprodutibilidade e consistência dos experimentos, precisamos garantir um mínimo de controle para que todos possam comparar coisas iguais. Para isso, usamos este parâmetro. Ele garante que os resultados sempre sejam iguais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retorno da função train_test_split\n",
      "[          0         1         2         3         4         5         6  \\\n",
      "8  0.215108  1.293524 -1.148588  1.409857 -0.153879  0.247565 -2.138733   \n",
      "9 -1.007224  1.297183  0.570126  0.977729  0.221430 -0.781725  1.760538   \n",
      "1  1.041501  0.492303 -1.141120  0.537813 -0.955247  1.092353 -0.515273   \n",
      "3 -1.115723  0.310569 -0.445182 -0.721336  1.867043 -0.036562 -1.228477   \n",
      "7  0.468312  0.159892 -0.323714  0.662747 -0.942503  0.214377  0.355391   \n",
      "4  1.329037  0.453575  0.651911 -0.547238 -0.236664 -0.629337 -0.650621   \n",
      "5 -1.511272 -0.004255  1.674363  0.092231 -0.444637  0.268949  2.066547   \n",
      "\n",
      "          7         8         9  \n",
      "8 -0.360338 -0.133181  1.021103  \n",
      "9 -1.256494 -0.018729  0.186629  \n",
      "1  0.463392 -0.451881  0.559118  \n",
      "3  0.180229  0.225222 -0.593937  \n",
      "7  1.513722 -0.649246 -0.828859  \n",
      "4 -0.208478 -0.176432  1.079129  \n",
      "5  1.594967 -1.586093  0.535195  ,           0         1         2         3         4         5         6  \\\n",
      "0  0.016541  0.941858  1.894961  0.288131  0.301205 -0.203974 -1.925187   \n",
      "6  2.930769  0.473638  0.131784 -0.515198  0.373591 -1.248871 -0.081810   \n",
      "2  0.649936  0.404966  0.019085 -2.030394 -0.729204 -0.031240 -0.460624   \n",
      "\n",
      "          7         8         9  \n",
      "0 -0.427590 -2.711001 -1.189263  \n",
      "6 -0.303669  1.478850 -0.140981  \n",
      "2  0.333989  0.300621 -0.667966  ]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rand_matrice = np.random.randn(100).reshape(10, 10) # cria uma tabela 10x10 aleatoria\n",
    "rand_vector = np.random.randn(100) # cria um vetor de tamanho 100 aleatorio\n",
    "\n",
    "# para melhor visualizacao, vamos criar um DataFrame e uma Series com os dados acima\n",
    "df_rand_matrice = pd.DataFrame(rand_matrice)\n",
    "s_rand_vector = pd.Series(rand_vector, name='rand_vector')\n",
    "\n",
    "print(\"Retorno da função train_test_split\")\n",
    "print(train_test_split(df_rand_matrice, test_size=0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que o dataframe foi separado em dois, o primeiro tem 75% dos dados totais e o segundo 25%, conforme especificamos em *test_size=0.25*. Podemos acessar diretamente esses dois dataframes da seguinte maneira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de treino\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.016541  0.941858  1.894961  0.288131  0.301205 -0.203974 -1.925187   \n",
      "3 -1.115723  0.310569 -0.445182 -0.721336  1.867043 -0.036562 -1.228477   \n",
      "4  1.329037  0.453575  0.651911 -0.547238 -0.236664 -0.629337 -0.650621   \n",
      "1  1.041501  0.492303 -1.141120  0.537813 -0.955247  1.092353 -0.515273   \n",
      "2  0.649936  0.404966  0.019085 -2.030394 -0.729204 -0.031240 -0.460624   \n",
      "9 -1.007224  1.297183  0.570126  0.977729  0.221430 -0.781725  1.760538   \n",
      "6  2.930769  0.473638  0.131784 -0.515198  0.373591 -1.248871 -0.081810   \n",
      "\n",
      "          7         8         9  \n",
      "0 -0.427590 -2.711001 -1.189263  \n",
      "3  0.180229  0.225222 -0.593937  \n",
      "4 -0.208478 -0.176432  1.079129  \n",
      "1  0.463392 -0.451881  0.559118  \n",
      "2  0.333989  0.300621 -0.667966  \n",
      "9 -1.256494 -0.018729  0.186629  \n",
      "6 -0.303669  1.478850 -0.140981  \n",
      "-----------------------\n",
      "Dataset de teste\n",
      "          0         1         2         3         4         5         6  \\\n",
      "7  0.468312  0.159892 -0.323714  0.662747 -0.942503  0.214377  0.355391   \n",
      "5 -1.511272 -0.004255  1.674363  0.092231 -0.444637  0.268949  2.066547   \n",
      "8  0.215108  1.293524 -1.148588  1.409857 -0.153879  0.247565 -2.138733   \n",
      "\n",
      "          7         8         9  \n",
      "7  1.513722 -0.649246 -0.828859  \n",
      "5  1.594967 -1.586093  0.535195  \n",
      "8 -0.360338 -0.133181  1.021103  \n"
     ]
    }
   ],
   "source": [
    "# criando duas variaveis diretamente com os retornos da funcao train_test_split\n",
    "X_train, X_test = train_test_split(df_rand_matrice, test_size=0.25)\n",
    "\n",
    "print('Dataset de treino')\n",
    "print(X_train)\n",
    "print('-----------------------')\n",
    "print('Dataset de teste')\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste rodar o pedaço de código acima várias vezes. Você terá um resultado diferente toda vez. Para garantirmos a reprodutibilidade, nós precisamos usar o parâmetro random_state. Rode o pedaço de código abaixo e veja que toda vez os resultados serão os mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de treino\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.016541  0.941858  1.894961  0.288131  0.301205 -0.203974 -1.925187   \n",
      "7  0.468312  0.159892 -0.323714  0.662747 -0.942503  0.214377  0.355391   \n",
      "2  0.649936  0.404966  0.019085 -2.030394 -0.729204 -0.031240 -0.460624   \n",
      "9 -1.007224  1.297183  0.570126  0.977729  0.221430 -0.781725  1.760538   \n",
      "4  1.329037  0.453575  0.651911 -0.547238 -0.236664 -0.629337 -0.650621   \n",
      "3 -1.115723  0.310569 -0.445182 -0.721336  1.867043 -0.036562 -1.228477   \n",
      "6  2.930769  0.473638  0.131784 -0.515198  0.373591 -1.248871 -0.081810   \n",
      "\n",
      "          7         8         9  \n",
      "0 -0.427590 -2.711001 -1.189263  \n",
      "7  1.513722 -0.649246 -0.828859  \n",
      "2  0.333989  0.300621 -0.667966  \n",
      "9 -1.256494 -0.018729  0.186629  \n",
      "4 -0.208478 -0.176432  1.079129  \n",
      "3  0.180229  0.225222 -0.593937  \n",
      "6 -0.303669  1.478850 -0.140981  \n",
      "-----------------------\n",
      "Dataset de teste\n",
      "          0         1         2         3         4         5         6  \\\n",
      "8  0.215108  1.293524 -1.148588  1.409857 -0.153879  0.247565 -2.138733   \n",
      "1  1.041501  0.492303 -1.141120  0.537813 -0.955247  1.092353 -0.515273   \n",
      "5 -1.511272 -0.004255  1.674363  0.092231 -0.444637  0.268949  2.066547   \n",
      "\n",
      "          7         8         9  \n",
      "8 -0.360338 -0.133181  1.021103  \n",
      "1  0.463392 -0.451881  0.559118  \n",
      "5  1.594967 -1.586093  0.535195  \n"
     ]
    }
   ],
   "source": [
    "# criando duas variaveis diretamente com os retornos da funcao train_test_split\n",
    "# e usando o random_state, geralmente usamos 0(zero) ou 42\n",
    "X_train, X_test = train_test_split(df_rand_matrice, test_size=0.25, random_state=42)\n",
    "\n",
    "print('Dataset de treino')\n",
    "print(X_train)\n",
    "print('-----------------------')\n",
    "print('Dataset de teste')\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos passar mais de um *array* para a função, apenas lembre-se que eles precisam ter o mesmo número de *samples*(linhas). Quando passamos mais de um *array* para ser dividido, a função nos retorna quatro divisões. Veja abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retorno da função quando passamos dois arrays\n",
      "[array([[ 0.05312393,  1.19683463, -1.263375  ,  0.89784222,  0.61426732,\n",
      "        -0.93299581, -0.85515003, -1.37055607,  1.07104538,  0.57921805],\n",
      "       [ 0.291998  ,  0.28598275, -0.58092087,  0.57425364,  0.29980821,\n",
      "         1.28883486,  0.98094781, -0.23790901,  0.83941905,  0.09310801],\n",
      "       [-0.36785336, -0.38372844,  0.09481585, -1.39334217,  0.05016527,\n",
      "        -0.79179101,  0.25517666,  0.61850601,  0.88594793, -0.26823136],\n",
      "       [-0.15649095,  0.30669315,  1.19695202,  0.3186359 ,  0.81778832,\n",
      "        -0.5196799 ,  0.8030573 , -0.6379218 , -1.85096432,  0.81531014],\n",
      "       [ 2.64515951,  0.33636202,  1.22012847, -0.58416251,  1.58154841,\n",
      "         0.25781472, -0.72275142,  0.26431562,  0.56119831,  0.43192633],\n",
      "       [-1.43311076,  0.0876731 , -0.2544631 ,  0.46695414, -1.69038255,\n",
      "         1.21662376,  1.0592311 , -0.12381539, -1.52218988,  0.96916589],\n",
      "       [-0.03464291, -1.48150497,  0.4367995 ,  0.05042059, -1.71228935,\n",
      "         0.50589935, -0.66130596,  0.48293906,  1.4539379 , -0.56673099]]), array([[-0.25123596, -2.98456514,  0.87220966, -0.37764112, -0.63493764,\n",
      "         0.19323789, -0.10551821, -1.39127196, -1.2903932 , -0.11794812],\n",
      "       [-1.06663233,  1.56935174, -1.24632075,  0.24618283,  0.32767638,\n",
      "        -1.43121748, -0.95866944,  0.57506988,  0.79438196,  0.32671688],\n",
      "       [-0.85954204, -0.3739659 ,  0.97136311,  0.12599554, -0.59919356,\n",
      "        -0.80996376,  1.54170301,  1.14147404,  0.77566762,  1.5475321 ]]), array([[ 0.053381  ],\n",
      "       [-1.42824336],\n",
      "       [ 1.21682211],\n",
      "       [ 0.13937597],\n",
      "       [-0.82417522],\n",
      "       [-0.04981044],\n",
      "       [ 1.92035272]]), array([[-1.6819969 ],\n",
      "       [-0.74818654],\n",
      "       [ 0.25516116]])]\n"
     ]
    }
   ],
   "source": [
    "# criando dados sinteticos com 10 samples\n",
    "rand_matrice = np.random.randn(100).reshape(10, 10) # 10 samples e 10 features\n",
    "rand_vector = np.random.randn(10).reshape(-1, 1) # 10 samples\n",
    "\n",
    "print(\"Retorno da função quando passamos dois arrays\")\n",
    "print(train_test_split(rand_matrice, rand_vector, test_size=0.25, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acessar diretamente os quatro retornos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design Matrix de Treino | Shape=(7, 10)\n",
      "[[ 0.53517623 -0.47173958 -1.17412855 -0.69155613 -0.32451712  0.53721869\n",
      "  -0.61189151 -0.48226986 -1.95927694 -1.58948218]\n",
      " [-0.14153574  0.58619921 -1.62577684 -0.07158337  0.05971679 -0.76533798\n",
      "   0.35090426  0.53564661 -0.80192126  0.04673181]\n",
      " [-1.3722665  -0.4049837   0.77813596  1.14995349  0.56473402  0.22966938\n",
      "   1.22377548  1.17153542 -0.23344727 -1.13393911]\n",
      " [-0.34506558 -0.75492208 -0.37554763 -1.19956725  0.25609548  0.12537742\n",
      "   0.74571082 -0.46904285  0.60750422 -0.38343654]\n",
      " [ 0.91079406  0.66618483 -0.77040014  1.52344959  0.47568555  0.15593878\n",
      "  -0.3599179  -2.40102332  1.58710098  1.54934098]\n",
      " [-0.36712636  0.18629837 -0.90564361 -0.89301429  1.23807391 -1.02482596\n",
      "   1.16066168  1.28661958  2.3200946  -0.54258834]\n",
      " [ 0.74583368  0.89185004  0.56672486  0.31990996  2.32861698 -0.55653318\n",
      "  -0.73124874 -0.75899319 -0.30916574  0.49500639]]\n",
      "\n",
      "Target Values de Treino | Shape=(7, 1)\n",
      "[[-0.58888023]\n",
      " [ 0.28381592]\n",
      " [ 1.83721831]\n",
      " [ 0.66835548]\n",
      " [ 1.27614228]\n",
      " [-0.80877056]\n",
      " [-0.38565041]]\n",
      "\n",
      "-----------------------\n",
      "\n",
      "Design Matrix de Teste | Shape=(3, 10)\n",
      "[[-1.10284707  0.09012594  2.03085221  0.01799503  0.47593299 -0.15164662\n",
      "   0.18267112 -0.31884219 -0.42226261 -0.88523545]\n",
      " [ 0.17747132 -0.48591444 -1.14002729 -2.25133152 -1.09984303 -1.92997195\n",
      "   0.52524277 -0.21886496  0.19842831  0.30930222]\n",
      " [-1.1035545   0.60755027 -0.32279669  0.42416094 -1.14703881 -0.92801799\n",
      "  -0.75178955 -1.10514632  0.85734984  0.23561305]]\n",
      "\n",
      "Target Values de Teste | Shape=(3, 1)\n",
      "[[-0.07427056]\n",
      " [ 0.52496768]\n",
      " [ 0.63102412]]\n"
     ]
    }
   ],
   "source": [
    "# criando dados sinteticos com 10 samples\n",
    "rand_matrice = np.random.randn(100).reshape(10, 10) # 10 samples e 10 features\n",
    "rand_vector = np.random.randn(10).reshape(-1, 1) # 10 samples\n",
    "\n",
    "# separando os dois arrays na proporcao 75% - 25%, sendo que 25% ficarão para testarmos algum estimator\n",
    "X_train, X_test, y_train, y_test = train_test_split(rand_matrice, rand_vector, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "print(f'Design Matrix de Treino | Shape={X_train.shape}')\n",
    "print(X_train)\n",
    "print(f'\\nTarget Values de Treino | Shape={y_train.shape}')\n",
    "print(y_train)\n",
    "\n",
    "print('\\n-----------------------')\n",
    "print(f'\\nDesign Matrix de Teste | Shape={X_test.shape}')\n",
    "print(X_test)\n",
    "print(f'\\nTarget Values de Teste | Shape={y_test.shape}')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linhas 29 e 32\n",
    "- Na linha 29 nós treinamos(.fit) o estimator apenas nos dados que chamamos de treino.\n",
    "- Na linha 32 nós fizemos previsões(.predict) em dados que nunca vimos, ou seja, os dados que separamos com a função *train_test_split()* e chamamos de dados de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando Classificação com Holdout \n",
    "\n",
    "Temos dois scripts, onde:\n",
    "- eval_same_data.py faz o seguinte:\n",
    "    - leitura dos dados com pd.read_csv()\n",
    "    - treina uma DecisionTreeClassifier em todos os dados que temos\n",
    "    - faz previsões nos mesmos dados que o algoritmo treinou\n",
    "    - avalia com a métrica Accuracy as previsões que são feitas nos mesmos dados que treinamos\n",
    "- eval_diff_data.py faz o seguinte:\n",
    "    - leitura dos dados com pd.read_csv()\n",
    "    - separa aleatoriamente 30% dos dados\n",
    "    - treina uma DecisionTreeClassifier em 70% que foram separados aleatoriamente\n",
    "    - faz previsões nos 30% de dados que foram separados e que o modelo nunca viu\n",
    "    - avalia com a métrica Accuracy as previsões que foram feitas nos dados que ele nunca viu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc nos mesmos dados que treinamos: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------eval_same_data_class.py------\n",
    "\n",
    "Script que treina e avalia uma DecisionTreeClassifier\n",
    "nos mesmos dados. Veja que a acuracia eh 100%\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "PATH_FILE = 'data/diabetes.csv'\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df_housing = pd.read_csv(PATH_FILE)\n",
    "\n",
    "X = df_housing.drop(columns='Outcome')\n",
    "y = df_housing.loc[:, 'Outcome']\n",
    "\n",
    "estimator = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "# fazendo previsoes nos mesmos dados que vimos\n",
    "y_pred = estimator.predict(X)\n",
    "\n",
    "# avaliando com a metrica Accuracy as previsoes que foram feitas\n",
    "# nos mesmos dados que treinamos\n",
    "acc = accuracy_score(y, y_pred)*100\n",
    "\n",
    "print(f'Acc nos mesmos dados que treinamos: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc em dados nunca vistos: 70.13%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------eval_same_data_class.py------\n",
    "\n",
    "Script que treina uma DecisionTreeClassifier em 70% dos\n",
    "dados e avalia nos 30% restantes. Veja como a acuracia \n",
    "eh diferente de 100%\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "PATH_FILE = 'data/diabetes.csv'\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df_housing = pd.read_csv(PATH_FILE)\n",
    "\n",
    "X = df_housing.drop(columns='Outcome')\n",
    "y = df_housing.loc[:, 'Outcome']\n",
    "\n",
    "# divindo X e y em uma proporcao de 70% para treino e 30% para testar\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "estimator = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "# aqui estamos treinado em apenas 70% dos dados\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "# fazendo previsoes nos outros 30% que o modelo nunca viu\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "# avaliando com a metrica Accuracy as previsoes feitas em dados que nunca vimos\n",
    "acc = accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "print(f'Acc em dados nunca vistos: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando Regressão e Classificação com Cross-Validation\n",
    "\n",
    "Vamos usar a função cross_val_score para retornar os resultados de um cross-validation. Temos alguns detalhes sobre ela que já iremos adiantar aqui.\n",
    "\n",
    "Sobre os parâmetros\n",
    "- scoring: se você deixar igual a None, ele usa o score default do próprio estimador\n",
    "    - no script cross_val_regression.py, usamos o estimador DecisionTreeRegressor, que tem como score default o $R^2$\n",
    "    - no script cross_val_classification.py, usamos o estimador DecisionTreeClassifier, que tem como score default a accuracy\n",
    "- cv: podemos passar muitas coisas para esse parâmetro, vamos ficar com o exemplo simples abaixo\n",
    "    - no script cross_val_regression.py, usamos $cv=5$, assim temos 5 folders no cross-validation\n",
    "    - no script cross_val_classification.py, usamos $cv=10$, assim temos 10 folders no cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores do Cross-validation\n",
      "[0.42 0.58 0.56 0.52 0.08]\n",
      "Media   : 0.43\n",
      "Desv Pad: 0.18\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------cross_val_regression.py------\n",
    "\n",
    "Usamos uma DecisionTreeRegressor e a funcao\n",
    "cross_val_score para retornar o resultado\n",
    "de um cross-validation com 5 folders\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "PATH_FILE = 'data/housing.csv'\n",
    "N_FOLDERS = 5 # quantidade de folders no cross-validation\n",
    "SCORING = None # faz com que cross_val_score use o score default do estimador\n",
    "\n",
    "df_housing = pd.read_csv(PATH_FILE)\n",
    "\n",
    "X = df_housing.drop(columns='MEDV')\n",
    "y = df_housing.loc[:, 'MEDV']\n",
    "\n",
    "estimator = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "# retornando resultado de um cross-validation com 5 folders\n",
    "# e scoring default r2 do estimador DecisionTreeRegressor\n",
    "scores = cross_val_score(estimator, X, y, scoring=SCORING, cv=N_FOLDERS)\n",
    "\n",
    "print('Scores do Cross-validation')\n",
    "print(scores.round(2))\n",
    "print(f'Media   : {scores.mean():.2f}')\n",
    "print(f'Desv Pad: {scores.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores do Cross-validation\n",
      "[67.53 72.73 67.53 59.74 68.83 67.53 80.52 76.62 65.79 75.  ]\n",
      "Media   : 70.18%\n",
      "Desv Pad: 5.74%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------cross_val_classification.py------\n",
    "\n",
    "Usamos uma DecisionTreeClassifier e a funcao\n",
    "cross_val_score para retornar o resultado\n",
    "de um cross-validation com 10 folders \n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "PATH_FILE = 'data/diabetes.csv'\n",
    "N_FOLDERS = 10 # quantidade de folders no cross-validation\n",
    "SCORING = None # faz com que cross_val_score use o score default do estimador\n",
    "\n",
    "df_housing = pd.read_csv(PATH_FILE)\n",
    "\n",
    "X = df_housing.drop(columns='Outcome')\n",
    "y = df_housing.loc[:, 'Outcome']\n",
    "\n",
    "estimator = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "# retornando resultado de um cross-validation com 10 folders\n",
    "# e scoring default accuracy do estimador DecisionTreeClassifier\n",
    "# ja multiplicamos por 100 para mostrar em porcentagem\n",
    "scores = cross_val_score(estimator, X, y, scoring=SCORING, cv=N_FOLDERS)*100\n",
    "\n",
    "print('Scores do Cross-validation')\n",
    "print(scores.round(2))\n",
    "print(f'Media   : {scores.mean():.2f}%')\n",
    "print(f'Desv Pad: {scores.std():.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dissecando cross_val_classification.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linhas [8, 22]\n",
    "Fazem parte dos requisitos básicos, caso não entenda o que está acontecendo nessas linhas de código, consulte as referências que estão nos requisitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linha 27\n",
    "A linha que realmente importa aqui. A função cross_val_score possui alguns parâmetros essenciais.\n",
    "- estimator: o estimador que vamos usar para fazer o cross-validation\n",
    "- X: Design Matrix X com as features\n",
    "- y: target Values y com os targets\n",
    "- scoring: a métrica que queremos usar para os resultados do cross-validation, aqui vamos usar None. Este faz com que a função use o score default do estimador que estamos usando\n",
    "- cv: podemos passar muitas coisas para esse parâmetro, vamos ficar no simples e passar um int igual a 5. Significa que faremos um cross-validation com 5 folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja a segunda saída, perceba que todos os valores estão negativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esquema Função cross-val-score \n",
    "\n",
    "Abaixo temos o estimador DecisionTreeClassifier que iremos usar e o dataset, que tem duas features e um target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DATA-ESTIMATOR](images/05_01_data_estimator.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodando e colocando os parâmetros da função cross_val_score\n",
    "- Estimador usado é o DecisionTreeClassifier, o score default desse estimador é a accuracy\n",
    "- Design Matrix X são as duas featuers Feat_1 e Feat_2\n",
    "- Target Values y é a coluna Target\n",
    "- Scoring igual a None signifca que vamos usar o score default do estimador que estivermos usando\n",
    "- CV igual a 5 é a quantidade de folders que vamos usar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CROSS-VAL-SCORE](images/05_02_cross_val_score.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo temos o retorno - os resultados são inventados - da função cross-val-score. Significa que\n",
    "- Primeira rodada acurácia foi de 0%\n",
    "- Segunda rodade de 0%\n",
    "- Terceira rodada de 50%\n",
    "- Quarta de 100%\n",
    "- Quinta de 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CROSS-VAL-SCORE-RESULTS](images/05_03_cross_val_score_results.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
