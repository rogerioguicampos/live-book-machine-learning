{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#O-que-veremos?\" data-toc-modified-id=\"O-que-veremos?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>O que veremos?</a></span></li><li><span><a href=\"#Requisitos-Básicos\" data-toc-modified-id=\"Requisitos-Básicos-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Requisitos Básicos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Teoria\" data-toc-modified-id=\"Teoria-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Teoria</a></span></li><li><span><a href=\"#Técnico\" data-toc-modified-id=\"Técnico-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Técnico</a></span></li></ul></li><li><span><a href=\"#Criando-Pipelines\" data-toc-modified-id=\"Criando-Pipelines-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Criando Pipelines</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sem-Pipeline\" data-toc-modified-id=\"Sem-Pipeline-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Sem Pipeline</a></span></li><li><span><a href=\"#Com-Pipeline\" data-toc-modified-id=\"Com-Pipeline-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Com Pipeline</a></span></li></ul></li><li><span><a href=\"#Dissecando-com_pipeline.py\" data-toc-modified-id=\"Dissecando-com_pipeline.py-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Dissecando com_pipeline.py</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que veremos? \n",
    "\n",
    "Em 99% dos modelos de Machine Learning criados(carece de fontes), nós teremos que pré-processar e transformar os dados antes deles serem passados para um estimador do *scikit-learn*.<br>\n",
    "\n",
    "O problema disso é que nós teremos muitas linhas de código com objetos que possuem os mesmos métodos .fit() e .transform() e um final com .fit() e .predict(). Nós aprenderemos a colocar todos esses objetos dentro um único PIPELINE, assim usaremos apenas o PIPELINE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requisitos Básicos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoria\n",
    "Não há nenhuma teoria básica que seja condição necessária para que você consiga seguir com esse notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnico \n",
    "- Python | Requisitos em **02-Python-Packages-Libraries/0-Python**\n",
    "    - Básico de Orientação a Objetos. Somente saber o que são objetos, classes, métodos, atributos etc. Nomenclatura e terminologia básicas\n",
    "    - Imports de bibliotecas\n",
    "- NumPy | Requisitos em **02-Python-Packages-Libraries/01-NumPy**\n",
    "    - Arrays\n",
    "    - Manipulação básica de arrays\n",
    "- Pandas | Requisitos em **02-Python-Packages-Libraries/02-Pandas**\n",
    "    - Leitura de dados\n",
    "    - Dataframes e Series\n",
    "    - Manipulação básica dos dois acima\n",
    "- Scikit-Learn | Requisitos em **02-Python-Packages-Libraries/03-Scikit-Learn**\n",
    "    - Transformadores e pré-processadores\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando Pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sem Pipeline\n",
    "\n",
    "Primeiro, vamos fazer um modelo sem usar o Pipeline e ver como o código ficaria.<br>\n",
    "\n",
    "Vamos usar o dataset [Titanic do Kaggle](https://www.kaggle.com/c/titanic), entre no link para saber mais sobre a competição no próprio [Kaggle](https://www.kaggle.com/).<br>\n",
    "\n",
    "Alguns pontos:\n",
    "- A coluna PassengerId será usada como index\n",
    "- Usaremos apenas as features Age e Fare, as duas serão nossa Design Matrix X\n",
    "    - Age tem dados faltantes\n",
    "- Survived é o nosso Target Values y\n",
    "- Não iremos separar os dados em treino e teste. Nunca faça isso, aqui é somente um exemplo para mostrarmos o funcionamento geral do Pipeline, depois iremos mostrar com profundidade tudo o que temos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de dados faltantes nas features\n",
      "Age     19.87\n",
      "Fare     0.00\n",
      "dtype: float64\n",
      "Veja que a feature Age tem ~20% de dados faltantes\n",
      "--------------------------------------------------\n",
      "\n",
      "Acc nos mesmos dados que treinamos: 65.43%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------sem_pipeline.py------\n",
    "\n",
    "Script que mostra duas transformacoes:\n",
    "    - Inserimos a media onde temos valores faltantes\n",
    "    - Fazer o StandardScaler dos dados apos inserir os dados faltantes\n",
    "Apos as duas transformacoes, nos usamos o estimador LogisticRegression\n",
    "Repare na quantidade de passos que devemos fazer.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "PATH_FILE = 'data/titanic.csv'\n",
    "USE_COLS = ['PassengerId', 'Survived', 'Age', 'Fare']\n",
    "\n",
    "df_titanic = pd.read_csv(PATH_FILE, usecols=USE_COLS, index_col='PassengerId')\n",
    "\n",
    "X = df_titanic.drop(columns='Survived')\n",
    "y = df_titanic.loc[:, 'Survived']\n",
    "\n",
    "print('Porcentagem de dados faltantes nas features')\n",
    "print(f'{(X.isna().mean()*100).round(2)}')\n",
    "print('Veja que a feature Age tem ~20% de dados faltantes')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# inserindo a media em dados faltantes\n",
    "# vamos usar primeiro .fit() e depois fit_transfor()\n",
    "imputer.fit(X)\n",
    "X_t_impute = imputer.transform(X)\n",
    "\n",
    "# fazendo o scaling dos dados com StandardScaler\n",
    "# apos inserirmos dados vazios\n",
    "scaler.fit(X_t_impute)\n",
    "X_t_scaler = scaler.transform(X_t_impute)\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_t_scaler, y)\n",
    "\n",
    "# vamos ver a acuracia do modelo\n",
    "# estamos fazendo isso nos mesmos \n",
    "# dados que treinamos, nunca faca isso\n",
    "acc = log_reg.score(X_t_scaler, y)*100\n",
    "print(f'\\nAcc nos mesmos dados que treinamos: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja a saída de cada transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>32.0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age     Fare\n",
       "PassengerId               \n",
       "1            22.0   7.2500\n",
       "2            38.0  71.2833\n",
       "3            26.0   7.9250\n",
       "4            35.0  53.1000\n",
       "5            35.0   8.0500\n",
       "...           ...      ...\n",
       "887          27.0  13.0000\n",
       "888          19.0  30.0000\n",
       "889           NaN  23.4500\n",
       "890          26.0  30.0000\n",
       "891          32.0   7.7500\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design Matrix Original\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.        ,  7.25      ],\n",
       "       [38.        , 71.2833    ],\n",
       "       [26.        ,  7.925     ],\n",
       "       ...,\n",
       "       [29.69911765, 23.45      ],\n",
       "       [26.        , 30.        ],\n",
       "       [32.        ,  7.75      ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design Matrix apos inserir a media\n",
    "# onde tinhamos dados faltantes\n",
    "X_t_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5924806 , -0.50244517],\n",
       "       [ 0.63878901,  0.78684529],\n",
       "       [-0.2846632 , -0.48885426],\n",
       "       ...,\n",
       "       [ 0.        , -0.17626324],\n",
       "       [-0.2846632 , -0.04438104],\n",
       "       [ 0.17706291, -0.49237783]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design Matrix apos inserir a media\n",
    "# e fazer o standard scaler\n",
    "X_t_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Com Pipeline\n",
    "\n",
    "Vamos reproduzir as mesmas transformações acima, mas dessa vez vamos usar o Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de dados faltantes nas features\n",
      "Age     19.87\n",
      "Fare     0.00\n",
      "dtype: float64\n",
      "Veja que a feature Age tem ~20% de dados faltantes\n",
      "--------------------------------------------------\n",
      "\n",
      "Acc nos mesmos dados que treinamos: 65.43%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------com_pipeline.py------\n",
    "Faremos exatamente as mesmas coisas que\n",
    "fizemos em sem_pipeline.py, mas vamos fazer\n",
    "uso do Pipeline.\n",
    "\n",
    "Veja como reduzimos tudo a apenas uma linha, o Pipeline\n",
    "ja treina e faz as transformacoes para a gente\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "PATH_FILE = 'data/titanic.csv'\n",
    "USE_COLS = ['PassengerId', 'Survived', 'Age', 'Fare']\n",
    "\n",
    "df_titanic = pd.read_csv(PATH_FILE, usecols=USE_COLS, index_col='PassengerId')\n",
    "\n",
    "X = df_titanic.drop(columns='Survived')\n",
    "y = df_titanic.loc[:, 'Survived']\n",
    "\n",
    "print('Porcentagem de dados faltantes nas features')\n",
    "print(f'{(X.isna().mean()*100).round(2)}')\n",
    "print('Veja que a feature Age tem ~20% de dados faltantes')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# criando o pipeline com os passos que queremos\n",
    "pipeline = Pipeline([('ImputeMean', imputer), # primeiro ele insere a media\n",
    "                     ('StandardScaler', scaler), # segundo ele faz o StandardScaler \n",
    "                     ('LogisticRegression', log_reg)]) # terceiro ele treina o estimador\n",
    "\n",
    "# usamos o .fit() e ele ja faz todos os passos acima\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "\n",
    "acc = pipeline.score(X, y)*100\n",
    "print(f'\\nAcc nos mesmos dados que treinamos: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja os passos(steps) do Pipeline que criamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passos(steps) do Pipeline\n",
      "Pipeline(steps=[('ImputeMean', SimpleImputer()),\n",
      "                ('StandardScaler', StandardScaler()),\n",
      "                ('LogisticRegression', LogisticRegression(random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "print('Passos(steps) do Pipeline')\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colocando a configurção display='diagram', conseguimos ver o Pipeline com uma representação em HTML quando usamos Jupyter-Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f9a547dc-6017-4c2e-a8f6-bed26ab71952\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f9a547dc-6017-4c2e-a8f6-bed26ab71952\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('ImputeMean', SimpleImputer()),\n",
       "                ('StandardScaler', StandardScaler()),\n",
       "                ('LogisticRegression', LogisticRegression(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c8206da6-906e-4f6b-836d-2af0a29c87ee\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c8206da6-906e-4f6b-836d-2af0a29c87ee\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"55039bbb-1d34-41cd-a022-6d79f684480e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"55039bbb-1d34-41cd-a022-6d79f684480e\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"71b3158b-e8f8-4c04-a403-dc4b5d977435\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"71b3158b-e8f8-4c04-a403-dc4b5d977435\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ImputeMean', SimpleImputer()),\n",
       "                ('StandardScaler', StandardScaler()),\n",
       "                ('LogisticRegression', LogisticRegression(random_state=42))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dissecando com_pipeline.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
