{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#O-que-veremos?\" data-toc-modified-id=\"O-que-veremos?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>O que veremos?</a></span></li><li><span><a href=\"#Requisitos-Básicos\" data-toc-modified-id=\"Requisitos-Básicos-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Requisitos Básicos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Teoria\" data-toc-modified-id=\"Teoria-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Teoria</a></span></li><li><span><a href=\"#Técnico\" data-toc-modified-id=\"Técnico-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Técnico</a></span></li></ul></li><li><span><a href=\"#Transformadores-e-pré-processadores\" data-toc-modified-id=\"Transformadores-e-pré-processadores-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Transformadores e pré-processadores</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dissecando-pre_process.py\" data-toc-modified-id=\"Dissecando-pre_process.py-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Dissecando pre_process.py</a></span></li></ul></li><li><span><a href=\"#Importante-1\" data-toc-modified-id=\"Importante-1-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Importante 1</a></span></li><li><span><a href=\"#Importante-2\" data-toc-modified-id=\"Importante-2-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Importante 2</a></span></li><li><span><a href=\"#Esquema-dos-métodos-.fit(),-.transform()-e-fit_transform()\" data-toc-modified-id=\"Esquema-dos-métodos-.fit(),-.transform()-e-fit_transform()-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Esquema dos métodos .fit(), .transform() e fit_transform()</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que veremos?\n",
    "\n",
    "Quando criamos um modelo de Machine Learning, este - praticamente 100% das vezes - é composto por mais do que apenas um estimador dando fit e predict. Geralmente, nós precisaremos transformar e pré-processar os dados de alguma maneira antes de usar um estimador.<br>\n",
    "\n",
    "Neste notebook nós iremos usar o StandarScaler. Todos os outros pré-processadores e transformadores obedecem as mesmas regras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requisitos Básicos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoria \n",
    "\n",
    "- Saber o que é e a importância de pré-processamento em modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnico \n",
    "- Python | Requisitos em **02-Python-Packages-Libraries/0-Python**\n",
    "    - Básico de Orientação a Objetos. Somente saber o que são objetos, classes, métodos, atributos etc. Nomenclatura e terminologia básicas\n",
    "    - Imports de bibliotecas\n",
    "- NumPy | Requisitos em **02-Python-Packages-Libraries/01-NumPy**\n",
    "    - Arrays\n",
    "    - Manipulação básica de arrays\n",
    "- Pandas | Requisitos em **02-Python-Packages-Libraries/02-Pandas**\n",
    "    - Leitura de dados\n",
    "    - Dataframes e Series\n",
    "    - Manipulação básica dos dois acima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformadores e pré-processadores \n",
    "\n",
    "No exemplo abaixo, nós usaremos o dataset *Pima Indians Diabetes*. Nesse dataset nós iremos pré-processar os dados com o **StandardScaler**. Não se preocupe em entender o que é e o motivo de usarmos esse passo de pré-processamento, concentre-se na técnica de como você pode fazê-lo. Mais tarde iremos destrinchar a teoria.\n",
    "\n",
    "Link para a página do Kaggle com informações adicionais sobre o dataset: [Pima Indians Diabetes Database - Kaggle](https://www.kaggle.com/uciml/pima-indians-diabetes-database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset que iremos trabalhar antes do pre-processamento\n",
      "     Glucose  BloodPressure   BMI  DiabetesPedigreeFunction\n",
      "0        148             72  33.6                     0.627\n",
      "1         85             66  26.6                     0.351\n",
      "2        183             64  23.3                     0.672\n",
      "3         89             66  28.1                     0.167\n",
      "4        137             40  43.1                     2.288\n",
      "..       ...            ...   ...                       ...\n",
      "763      101             76  32.9                     0.171\n",
      "764      122             70  36.8                     0.340\n",
      "765      121             72  26.2                     0.245\n",
      "766      126             60  30.1                     0.349\n",
      "767       93             70  30.4                     0.315\n",
      "\n",
      "[768 rows x 4 columns]\n",
      "\n",
      "Dataset apos o pre-processamento\n",
      "[[ 0.84832379  0.14964075  0.20401277  0.46849198]\n",
      " [-1.12339636 -0.16054575 -0.68442195 -0.36506078]\n",
      " [ 1.94372388 -0.26394125 -1.10325546  0.60439732]\n",
      " ...\n",
      " [ 0.00330087  0.14964075 -0.73518964 -0.68519336]\n",
      " [ 0.1597866  -0.47073225 -0.24020459 -0.37110101]\n",
      " [-0.8730192   0.04624525 -0.20212881 -0.47378505]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------pre_process.py------\n",
    "\n",
    "Script basico para leitura e pre-processamento\n",
    "das features numericas com StandardScaler\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "PATH_FILE = 'data/diabetes.csv'\n",
    "USE_COLS = ['Glucose', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction']\n",
    "\n",
    "df_diabetes = pd.read_csv(PATH_FILE, usecols=USE_COLS)\n",
    "\n",
    "print('Dataset que iremos trabalhar antes do pre-processamento')\n",
    "print(df_diabetes)\n",
    "print()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_diabetes_t = scaler.fit_transform(df_diabetes)\n",
    "\n",
    "print('Dataset apos o pre-processamento')\n",
    "print(df_diabetes_t)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissecando pre_process.py \n",
    "\n",
    "Vamos nos concentrar nas linhas 20 e 21, já que as outras fazem parte dos requisitos básicos para esse notebook.\n",
    "Na linhas 20, nós instanciamos o StandardScaler. Caso você está aqui se aventurando e não faz ideia do que é isso, imagine que nós temos agora uma variável **scaler**, que representa o StandardScaler, olhe as duas saídas abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script para mostrar o tipo\n",
    "e o que é devolvido quando \n",
    "rodamos a variavel scaler\n",
    "\"\"\"\n",
    "\n",
    "print(type(scaler))\n",
    "print(scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual a vantagem disso? Nossa variável agora poderá usar três métodos muito importantes e que usaremos com bastante frequência, são eles:\n",
    "- .fit(): apenas aprende o que ele deve aprender com os dados que foram passados. No caso do StandardScaler é a média e o desvio padrão dos dados\n",
    "- .transform(): efetivamente faz a transformação dos dados. Com o StandardScaler após o .fit() nós pegamos a média $\\bar{u}$ e o desvio padrão $\\bar{s}$ aprendidos e transformamos cada sample $x$ da feature da seguinte maneira $$z = \\frac{(x - \\bar{u})}{\\bar{s}}$$\n",
    "- .fit_transform(): treina e transforma o que você passa para ele. Ou seja, ela aprende o que deve aprender com os dados que foram passados e já realiza a transformação desses mesmos dados.\n",
    "\n",
    "Veja o exemplo abaixo, nós usamos primeiro apenas o método .fit(), mostramos a média e o desvio padrão que ele calculou e depois em posse desses dois, nós fazemos a transformação $$z = \\frac{(x - \\bar{u})}{\\bar{s}}$$ para cada feature com o método .transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media e Desvio Padrao calculados na mao\n",
      "Media: Glucose    120.894531\n",
      "dtype: float64\n",
      "Desv Pad: Glucose    31.972618\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script basico para mostrar a\n",
    "media e o desvio padrao de uma unica \n",
    "feature.\n",
    "O calculo foi feito para compararmos com\n",
    "que e achado pelo StandardScaler\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "PATH_FILE = 'data/diabetes.csv'\n",
    "USE_COLS = ['Glucose']\n",
    "\n",
    "one_feature = pd.read_csv(PATH_FILE, usecols=USE_COLS)\n",
    "\n",
    "mean = one_feature.mean()\n",
    "std = one_feature.std()\n",
    "\n",
    "print('Media e Desvio Padrao calculados na mao')\n",
    "print(f'Media: {mean}')\n",
    "print(f'Desv Pad: {std}')\n",
    "print()\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima temos o cálculo da média e do desvio padrão \"na mão\" da feature Glucose.<br> \n",
    "Vamos dar apenas um fit com StandardScaler, lembre-se, 99% das vezes você usará o fit_transform(), que já é o treino e a transformação dos dados. Usando apenas o fit() o StandardScaler apenas treina/aprende - no caso específico dessse pré-processador - a média e o desvio padrão dos dados. Veja abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O que foi aprendido pelo StandardScaler\n",
      "Media   : [120.89453125]\n",
      "Desv Pad: [31.95179591]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dando apenas fit com o StandardScaler.\n",
    "Nesse caso ele apenas aprende a media\n",
    "e o desvio padrao dos dados que foram passados\n",
    "e nao realiza nenhuma transformacao\n",
    "\n",
    "\"\"\"\n",
    "# treinando o StandardScaler\n",
    "scaler.fit(one_feature)\n",
    "\n",
    "print(\"O que foi aprendido pelo StandardScaler\")\n",
    "print(f\"Media   : {scaler.mean_}\")\n",
    "print(f\"Desv Pad: {scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que os resultados são os mesmos nas duas situações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print das 10 primeiras linhas transformadas\n",
      "[[ 0.84832379]\n",
      " [-1.12339636]\n",
      " [ 1.94372388]\n",
      " [-0.99820778]\n",
      " [ 0.5040552 ]\n",
      " [-0.15318486]\n",
      " [-1.34247638]\n",
      " [-0.184482  ]\n",
      " [ 2.38188392]\n",
      " [ 0.12848945]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Apos o scaler ser treinado\n",
    "e aprender a media e o desvio padrao,\n",
    "nos usamos o transform para efetivamente\n",
    "mudar os dados\n",
    "\n",
    "\"\"\"\n",
    "# transformando os dados\n",
    "one_feature_trans = scaler.transform(one_feature)\n",
    "print('Print das 10 primeiras linhas transformadas')\n",
    "print(one_feature_trans[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos exemplos acima, nós tivemos que fazer dois passos, primeiro nós treinamos com o método .fit(). Aqui, no caso do StandardScaler, nós aprendemos a média e o desvio padrão dos dados. Depois que aprendemos, nós usamos o método .transform() para efetivamente fazer uma transformação nos dados.<br>\n",
    "\n",
    "Temos dois passos a serem feitos que podem ser juntados num único método, o fit_transform. O script pre-process.py mostra isso.<br>\n",
    "\n",
    "Após a transformação, os dados ficam com média igual a zero e desvio padrão igual a um. Veja as saídas abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media: -0.00\n",
      "Std: 1.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Apos a transformacao dos dados, estes passam\n",
    "a ter media igual a zero e desvio padrao igual a um\n",
    "\n",
    "\"\"\"\n",
    "mean_pos_transf = one_feature_trans.mean()\n",
    "std_pos_transf = one_feature_trans.std()\n",
    "\n",
    "print(f'Media: {mean_pos_transf:.2f}')\n",
    "print(f'Std: {std_pos_transf:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importante 1\n",
    "Vamos adiantar uma coisa aqui, você nunca deve usar o fit() ou o fit_transform() em dados de teste. REPITA COMIGO, NUNCA USAREI O FIT, ou seja, NUNCA TREINAREI/APRENDEREI COM OS DADOS DE TESTE, SOMENTE NOS DADOS DE TREINO. Por isso os dados de treino têm esse nome, servem para treinar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importante 2 \n",
    "Cada transformador e pré-processador aprende e transforma os dados de maneiras diferentes. No caso do StandardScaler temos uma coisa no caso do PowerTransform, temos outra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esquema dos métodos .fit(), .transform() e fit_transform()\n",
    "\n",
    "Vamos fazer um esquema para mostrar melhor como funciona um transformador/pré-processador no scikit-learn.<br>\n",
    "\n",
    "Na imagem abaixo, nós instanciamos o StandardScaler e mostramos os dados que iremos trabalhar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SCALE-DATA](images/03_01_scale_data.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, temos:\n",
    "- Passo 1: usamos o método .fit() nos dados que temos\n",
    "- Passo 2: a média e o desvio padrão que foram aprendidos com os dados\n",
    "- Passo 3: com os atributos .mean_ e .scale_, nós conseguimos acesasr a média e o desvio padrão calculados\n",
    "- Passo 4: após treinarmos, usamos o .transform() nos dados\n",
    "- Passo 5: método .transform() nos retorna os dados transformados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SCALE-DATA](images/03_02_sc_fit_and_transf.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
